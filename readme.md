# Микросервисы для машинного обучения

## Обзор

Система состоит из 5 микросервисов:

```
┌─────────────────────────────────────────────────────────┐
│                 Viz (служба визуализации)               │
└─────────────────────────┬───────────────────────────────┘
                          │
┌─────────────────────────▼───────────────────────────────┐
│                       Web Master                        │
│                      (Port 8000)                        │
└──────┬─────────────────┬────────────────┬───────────────┘
       │                 │                │
┌───────▼──────┐  ┌───────▼──────┐  ┌─────▼────────┐
│  Collector   │  │   Storage    │  │  ML Service  │
│  Port 8001   │  │  Port 8002   │  │  Port 8003   │
└──────────────┘  └──────────────┘  └──────────────┘
```

## Описание служб

### 1. Collector (сборщик данных) (порт 8001)
**Назначение**: служба сбора данных, предоставляющая батчи датасета «Титаник».

**Основные функции**:
- Извлечение батчей данных с заданным размером.
- Ведение журнала всех обращений к данным.
- API с информацией о датасете.

**API**:
- `GET /batch?size=100&offset=0` — получение пакета данных
- `GET /info` — получение информации о наборе данных
- `POST /reset` — сброс смещения до начала

### 2. Storage (хранилище данных) (порт 8002)
**Назначение**: центральное хранилище метаданных и система управления файлами с использованием SQLite.
База данных на основе SQLAlchemy

**Функции**:
- Хранение файлов
- Операции CRUD для наборов данных, моделей и запусков
- Отслеживание запусков для операций обучения и инференса
- Возможность загрузки и скачивания файлов

**API**:
- `/files`, `/datasets`, `/models`, `/runs` - Операции CRUD
- `/upload/dataset` — загрузка CSV-файлов
- `/datasets/{id}/download`, `/models/{id}/download` — загрузка файлов

### 3. Служба ML (порт 8003)
**Назначение**: обучение и инференс

**Ключевые особенности**:
- Поддержка нескольких типов моделей:
  - Логистическая регрессия
  - Случайный лес
  - K-ближайших соседей
- Настраиваемые гиперпараметры
- Отслеживание прогресса с помощью событий, отправляемых сервером (SSE)
- Автоматическая предварительная обработка набора данных Titanic
- Сохранение модели с метаданными
- Метрики и важность признаков


**API**:
- `POST /train` — запуск обучения модели
- `POST /infer` — запуск инференса
- `GET /progress/{run_id}` — SSE для отслеживания прогресса обучения

### 4. Веб-мастер (порт 8000)
**Назначение**: служба взаимодействия с API и управления системой.

**Для чего нужен**:
- Единая точка входа для всех запросов клиентов
- Маршрутизация запросов
- Мониторинг работоспособности всех сервисов
- Запуск сценариев

**API**:
- `POST /scenarios/collect-and-store` - Сценарий 1
- `POST /scenarios/train-model` - Сценарий 2
- `POST /scenarios/infer-model` - Сценарий 3
- `GET /scenarios/report/{model_id}` - Сценарий 4
- `GET /health` - Проверка работоспособности системы

### 5. Визуализация (порт 3000)
**Назначение**: интерактивный веб-интерфейс на Svelte

**Основные функции**:
- Выполнение сценариев
- Мониторинг прогресса сервиса ML с помощью SSE
- Создание отчетов по моделям
- Управление наборами данных, моделями и запусками

## Сценарии использования

### Сценарий 1: Сбор и хранение
**Цель**: Получить данные из коллектора и сохранить в хранилище.

**Процесс**:
1. Выберите размер пакета (количество строк).
2. Нажмите «Collect & Store».
3. Система получает данные из коллектора.
4. Автоматически выполняет предварительную обработку и сохраняет в хранилище.
5. Создает запись метаданных набора данных.

**Вызов API**:
```bash
curl -X POST http://localhost:8000/scenarios/collect-and-store \
  -H «Content-Type: application/json» \
  -d „{«batch_size»: 100}“
```

### Сценарий 2: Обучение модели
**Цель**: Обучить модель машинного обучения на основе сохраненного набора данных.

**Процесс**:
1. Выбрать набор данных из хранилища
2. Выбрать тип модели (логистическая регрессия, случайный лес или KNN)
3. Настроить гиперпараметры
4. Нажать «Train Model»
5. Отслеживать прогресс в режиме реального времени
6. Модель сохраняется с метриками и метаданными

**Поддерживаемые модели и гиперпараметры**:
- **Логистическая регрессия**: `max_iter`, `C`
- **Случайный лес**: `n_estimators`, `max_depth`
- **KNN**: `n_neighbors`, `weights`

**Вызов API**:
```bash
curl -X POST http://localhost:8000/scenarios/train-model \
  -H «Content-Type: application/json» \
  -d '{
    «dataset_id»: 1,
    «model_type»: «RandomForest»,
    «hyperparameters»: {„n_estimators“: 100, «max_depth»: 10}
  }'
```


### Сценарий 3: Вывод модели
**Цель**: Использование обученной модели для прогнозирования новых данных.

**Процесс**:
1. Выберите обученную модель.
2. Предоставьте входные данные (текст CSV или загрузка файла).
3. Нажмите «Run Inference».
4. Наблюдайте за ходом выполнения.
5. Результаты сохраняются в хранилище.

**Формат ввода**: CSV со столбцами: `Pclass,Sex,Age,SibSp,Parch,Fare,Embarked`
- Sex: 0=женский, 1=мужской
- Embarked: 0=S, 1=C, 2=Q

**Вызов API**:
```bash
curl -X POST http://localhost:8000/scenarios/infer-model \
  -H «Content-Type: application/json» \
  -d '{
    «model_id»: 1,
    «data»: «Pclass,Sex,Age,SibSp,Parch,Fare,Embarked\n3,1,22,1,0,7.25,2»
  }'
```

### Сценарий 4: Создание отчета
**Цель**: Создание подробного отчета о качестве модели.

**Содержание отчета**:
- Метаданные модели (название, тип, версия, дата создания)
- Показатели производительности (точность, пропорции разделения на обучающую и тестовую выборки)
- Использованные гиперпараметры
- Важность признаков (для поддерживаемых моделей)
- Отчет по классификации (точность, полнота, F1-показатель)
- Confusion Matrix

**Вызов API**:
```bash
curl http://localhost:8000/scenarios/report/1
```

## Развертывание

### Необходимые условия
- Установлены Docker и Docker Compose
- Доступно не менее 2 ГБ ОЗУ
- Доступны порты 8000-8003 и 5000

### Быстрый старт

1. **Склонируйте репозиторий и подготовьте данные**:
```bash
# Создайте папки
mkdir -p collector/data
mkdir -p collector/logs
mkdir -p storage/logs
mkdir -p ml_service/logs
mkdir -p web_master/logs

# Загрузите датасет Titanic
cd collector/data
wget https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv
cd ../..
```

2. **Соберите и запустите все службы**:
```bash
docker compose up --build
```

3. **Доступ к службам**:
- Фронтенд: http://localhost:5000
- API веб-мастера: http://localhost:8000
- Коллектор: http://localhost:8001
- Хранилище: http://localhost:8002
- Служба ML: http://localhost:8003

4. **Проверка работоспособности служб**:
```bash
curl http://localhost:8000/health
```


### Режим разработки

Чтобы запустить службы по отдельности для разработки:

```bash
# Терминал 1 - Collector
cd collector
pip install -r requirements.txt
python app.py

# Терминал 2 - Storage
cd storage
pip install -r requirements.txt
python app.py

# Терминал 3 - ML Service
cd ml_service
pip install -r requirements.txt
python app.py

# Терминал 4 - Web Master
cd web_master
pip install -r requirements.txt
python app.py

# Терминал 5 - Frontend
cd viz
npm install
npm run dev
```

### Конфигурация

Каждый сервис имеет файл `config.yaml` для настройки:

**Collector** (`collector/config.yaml`):
```yaml
service:
  port: 8001
data:
  source_path: «data/titanic.csv»
  default_batch_size: 100
```

**Хранилище** (`storage/config.yaml`):
```yaml
service:
  port: 8002
database:
  url: «sqlite:///./db/storage.db»
```

**Служба ML** (`ml_service/config.yaml`):
```yaml
service:
  port: 8003
services:
  storage_url: «http://storage:8002»
```

**Веб-мастер** (`web_master/config.yaml`):
```yaml
service:
  port: 8000
services:
  collector_url: «http://collector:8001»
  storage_url: «http://storage:8002»
  ml_service_url: «http://ml_service:8003»
```

## Техническая реализация

### Технологический стек
- **Бэкэнд**: Python 3.10, FastAPI, SQLAlchemy
- **ML**: scikit-learn, pandas, numpy
- **Фронтенд**: Svelte 5 (Runes), TypeScript, Tailwind CSS, Axios
- **Контейнеризация**: Docker, docker-compose
- **База данных**: SQLite
- **Коммуникация**: REST API, Server-Sent Events (SSE)

### Поток данных

1. **Сбор данных**:
```
  Viz → Web Master → Collector → Web Master → Storage
  ```

2. **Обучение**:
   ```
   Viz → Web Master → Storage (получение набора данных) → ML Service → Storage (сохранение модели)
                ↓
           Обновления прогресса (SSE)
   ```

3. **Инференс**:
   ```
   Viz → Web Master → ML Service (загрузка модели) → Storage (сохранение результатов)
                ↓
           Обновления прогресса (SSE)
   ```

### Предварительная обработка данных

Служба ML автоматически выполняет предварительную обработку набора данных Titanic:
- Удаляет ненужные столбцы (PassengerId, Name, Ticket, Cabin)
- Заполняет пропущенные значения медианой/модой
- Кодирует категориальные переменные (Sex, Embarked)
- Разделяет на обучающий и тестовый наборы (80/20)

### Версии моделей

Версии моделей обозначаются следующим образом:
- Именуются на основе временных меток: `{ModelType}_{YYYYMMDD_HHMMSS}`
- Хранятся в метаданных с гиперпараметрами и метриками
- Сохраняются в файлах с помощью pickle
- Используют базу данных SQLite для поиска

### Обработка ошибок

Все службы реализуют:
- Блоки try-catch для всех операций
- Обработку исключений HTTP с подробными сообщениями
- Ведение журналов в файлах

## Документация по API

Когда система запущена, можно открыть интерактивную документацию по API:
- Web Master: http://localhost:8000/docs
- Collector: http://localhost:8001/docs
- Storage: http://localhost:8002/docs
- ML Service: http://localhost:8003/docs

## Мониторинг и журналы

Журналы хранятся в каталоге `logs/` каждой службы:
- `collector/logs/collector.log`
- `storage/logs/storage.log`
- `ml_service/logs/ml_service.log`
- `web_master/logs/web_master.log`

Просмотр журналов во время работы служб:
```bash
docker compose logs -f [service_name]
```

